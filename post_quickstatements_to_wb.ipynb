{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhatfi/colab/blob/main/post_quickstatements_to_wb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lAxWMP15ZofD"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uK99N4bLZ1__"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xic-_snBZ5NL"
      },
      "outputs": [],
      "source": [
        "service = build('drive', 'v3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NaT5r5mnxxSP"
      },
      "outputs": [],
      "source": [
        "SPLIT_FILES_SOURCE = {'BETA': '187KTNwJ2LZXf5d8WAFO1qnP6g8Yqderw',\n",
        "                      'BITECA': '',\n",
        "                      'BITAGAP': ''}\n",
        "\n",
        "SPLIT_FILES_PROCESSED= {'BETA': '1lc-XTCm9lSAfO6xIxxQ5K_4LzHhj3nPl',\n",
        "                           'BITECA': '',\n",
        "                           'BITAGAP': ''}\n",
        "WB_CONFIGS = {\n",
        "    'pb.cloud': {\n",
        "        'MEDIAWIKI_API_URL': 'https://pbsandbox.wikibase.cloud/qs/api.php',\n",
        "        'WB_USER': 'pb.cloud.user',\n",
        "        'WB_PASSWORD': 'pb.cloud.password',\n",
        "        'WB_TOKEN': 'pb.cloud.token'\n",
        "    },\n",
        "    'pb.cog': {\n",
        "        'MEDIAWIKI_API_URL': \"https://philobiblon.cog.berkeley.edu/qs/api.php\",\n",
        "        'WB_USER': 'pb.cog.user',\n",
        "        'WB_PASSWORD': 'pb.cog.password',\n",
        "        'WB_TOKEN': 'pb.cog.token',\n",
        "    },\n",
        "        'factgrid': {\n",
        "        'MEDIAWIKI_API_URL': \"https://database.factgrid.de/qs/api.php\",\n",
        "        'WB_USER': 'factgrid.user',\n",
        "        'WB_PASSWORD': 'factgrid.password',\n",
        "        'WB_TOKEN': 'factgrid.token',\n",
        "    }\n",
        "}\n",
        "\n",
        "# Manually update bibliography, table and instance that is to be updated\n",
        "bibliography = 'BETA' # BETA BITECA BITAGAP\n",
        "table = 'geography' # 'geography' 'analytic' 'library' 'ms_ed' 'biographies' 'copies' 'institutions' 'subject' 'uniform_title'\n",
        "instance = \"pb.cog\" # pb.cloud pb.cog factgrid\n",
        "batch_id = ''\n",
        "start_time = time.time()\n",
        "elapsed_time = 0\n",
        "max_seconds = 36000\n",
        "complete_status = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iFun94tv9TTp"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "URL = WB_CONFIGS[instance]['MEDIAWIKI_API_URL']\n",
        "WB_USER = userdata.get(WB_CONFIGS[instance]['WB_USER'])\n",
        "WB_PASSWORD = userdata.get(WB_CONFIGS[instance]['WB_PASSWORD'])\n",
        "WB_TOKEN = userdata.get(WB_CONFIGS[instance]['WB_TOKEN'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ROJUV1wB8cEQ"
      },
      "outputs": [],
      "source": [
        "def time_check():\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
        "    return elapsed_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eeJGaYdvlDQy"
      },
      "outputs": [],
      "source": [
        "def get_batch_status(batch_id):\n",
        "    batch_status_command = f\"curl {URL} -d action=get_batch_info -d batch={batch_id}\"\n",
        "    batch_status = subprocess.run(batch_status_command, capture_output=True, text=True, shell=True)\n",
        "    try:\n",
        "        data = json.loads(batch_status.stdout)\n",
        "        batch_status = data[\"data\"][str(batch_id)][\"batch\"][\"status\"]\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error parsing JSON output:\", batch_status.stdout)\n",
        "    try:\n",
        "        error_count = data[\"data\"][str(batch_id)][\"commands\"]['ERROR']\n",
        "    except:\n",
        "        error_count = 0\n",
        "    return batch_status, error_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k0tPgYSQzTpy"
      },
      "outputs": [],
      "source": [
        "def move_file(source_id, destination_id, file_name, file_id):\n",
        "    file = service.files().get(fileId=file_id, fields='parents').execute()\n",
        "    previous_parents = \",\".join(file.get('parents'))\n",
        "    file = service.files().update(fileId=file_id,\n",
        "                                  addParents=destination_id,\n",
        "                                  removeParents=previous_parents,\n",
        "                                  fields='id, parents').execute()\n",
        "\n",
        "    print(f\"File '{file_name}' moved to folder with ID '{destination_id}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "AdmASJlTfZJV",
        "outputId": "6e7656d1-5f1d-46aa-af69-f092dabe56d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Items:\n",
            "split_beta_geography_qs_6.qs (1w0FdsXXrphidh8Vgt1jht3NYcX09pMeF)\n",
            "split_beta_geography_qs_5.qs (1tCKw-YFXvxzEO2k-K3_em1CQwHMkkDBK)\n",
            "split_beta_geography_qs_4.qs (1QYRzLuBj74Z39NnrUlrYzDghMN75eHkY)\n",
            "split_beta_geography_qs_3.qs (1agutIVihgjPOuXCjDuvAwedGF5ANszKq)\n",
            "split_beta_geography_qs_2.qs (1gZkRXH3cCgmmHjtIlCOmwQ7oICHN1UIP)\n",
            "split_beta_geography_qs_1.qs (10lc16SayO0AYjuAk03SX_FBhE3d1h2fJ)\n",
            "split_beta_geography_qs_0.qs (13F9Ro3ws2KMmrRNBstsc6cVCd95Djeid)\n",
            "Split Files Done (1lc-XTCm9lSAfO6xIxxQ5K_4LzHhj3nPl)\n",
            "[{'id': '1w0FdsXXrphidh8Vgt1jht3NYcX09pMeF', 'name': 'split_beta_geography_qs_6.qs'}, {'id': '1tCKw-YFXvxzEO2k-K3_em1CQwHMkkDBK', 'name': 'split_beta_geography_qs_5.qs'}, {'id': '1QYRzLuBj74Z39NnrUlrYzDghMN75eHkY', 'name': 'split_beta_geography_qs_4.qs'}, {'id': '1agutIVihgjPOuXCjDuvAwedGF5ANszKq', 'name': 'split_beta_geography_qs_3.qs'}, {'id': '1gZkRXH3cCgmmHjtIlCOmwQ7oICHN1UIP', 'name': 'split_beta_geography_qs_2.qs'}, {'id': '10lc16SayO0AYjuAk03SX_FBhE3d1h2fJ', 'name': 'split_beta_geography_qs_1.qs'}, {'id': '13F9Ro3ws2KMmrRNBstsc6cVCd95Djeid', 'name': 'split_beta_geography_qs_0.qs'}]\n",
            "List of all files to be processed: ['split_beta_geography_qs_0.qs', 'split_beta_geography_qs_1.qs', 'split_beta_geography_qs_2.qs', 'split_beta_geography_qs_3.qs', 'split_beta_geography_qs_4.qs', 'split_beta_geography_qs_5.qs', 'split_beta_geography_qs_6.qs']\n",
            "Elapsed time: 756.9880504608154 seconds\n",
            "split_beta_geography_qs_0.qs (13F9Ro3ws2KMmrRNBstsc6cVCd95Djeid)\n",
            "Downloading file: split_beta_geography_qs_0.qs\n",
            "Download 100%.\n",
            "File 'split_beta_geography_qs_0.qs' downloaded successfully.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'int' object has no attribute 'stderr'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5fa3ef20df35>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m#if post_qs.returncode != 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpost_qs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error executing curl command:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_qs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'stderr'"
          ]
        }
      ],
      "source": [
        "path_id = SPLIT_FILES_SOURCE[str(bibliography)]\n",
        "destination_id = SPLIT_FILES_PROCESSED[str(bibliography)]\n",
        "\n",
        "# Check for files in source directory\n",
        "results = service.files().list(q=f\"'{path_id}' in parents and trashed=false\", pageSize=1000, fields=\"nextPageToken, files(id, name)\").execute()\n",
        "items = results.get('files', [])\n",
        "if not items:\n",
        "    print('No items found.')\n",
        "else:\n",
        "    print('Items:')\n",
        "    for item in items:\n",
        "        print(u'{0} ({1})'.format(item['name'], item['id']))\n",
        "\n",
        "item_dict = [item for item in items if isinstance(item, dict)][0]\n",
        "table_items = [item for item in items if item['name'].endswith('.qs')]\n",
        "print(table_items)\n",
        "\n",
        "# Sort table items by split number\n",
        "table_items.sort(key=lambda x: int(x['name'].split('_')[4].split('.')[0]) if len(x['name'].split('_')) >= 4 else 0, reverse=False)\n",
        "names = [item['name'] for item in table_items]\n",
        "print(f'List of all files to be processed: {names}')\n",
        "\n",
        "# Loop through sorted items and process\n",
        "elapsed_time = time_check() # Get elapsed time so far to start\n",
        "while elapsed_time < max_seconds and not complete_status:\n",
        "    for table_item in table_items:\n",
        "        date = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "        batchname = f'{bibliography}_{table}_{date}'\n",
        "        print(u'{0} ({1})'.format(table_item['name'], table_item['id']))\n",
        "        file_id = table_item['id']\n",
        "        file_name = table_item['name']\n",
        "        # Download the file\n",
        "        print(f'Downloading file: {file_name}')\n",
        "        request = service.files().get_media(fileId=file_id)\n",
        "        fh = io.BytesIO()\n",
        "        downloader = MediaIoBaseDownload(fh, request)\n",
        "        done = False\n",
        "        while done is False:\n",
        "            status, done = downloader.next_chunk()\n",
        "            print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "\n",
        "        # Save the file to your Colab environment\n",
        "        with open(file_name, 'wb') as f:\n",
        "            f.write(fh.getbuffer())\n",
        "            print(f\"File '{file_name}' downloaded successfully.\")\n",
        "\n",
        "        # Run curl command submitting batch\n",
        "        curl_command = f'curl {URL} -d action=import -d submit=1 -d format=v1 -d username={WB_USER} -d batchname={batchname} --data-raw token=\\'{WB_TOKEN}\\' --data-urlencode data@{file_name}'\n",
        "        post_qs = subprocess.run(curl_command, capture_output=True, text=True, shell=True)\n",
        "        time.sleep(10) # Wait for batch to initiate\n",
        "        if post_qs.returncode != 0:\n",
        "            print(\"Error executing curl command:\", post_qs.stderr)\n",
        "            exit(1)\n",
        "        try:\n",
        "            data = json.loads(post_qs.stdout)\n",
        "            batch_id = data[\"batch_id\"]\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Error parsing JSON output for {batch_id}:\", post_qs.stdout)\n",
        "            continue\n",
        "        print(f\"Batch ID: {batch_id}\")\n",
        "        status = get_batch_status(batch_id)\n",
        "        while status != \"DONE\":\n",
        "            print(f'Batch import {batch_id} still running, sleeping for 10 minutes')\n",
        "            time.sleep(600)\n",
        "            print(\"Checking batch status\")\n",
        "            status, error_count = get_batch_status(batch_id)\n",
        "        print(f'Batch import {batch_id} complete with status {status}')\n",
        "        print(f'Batch {batch_id} had {error_count} errors')\n",
        "\n",
        "        # move to completed folder after processing\n",
        "        move_file(path_id, destination_id, file_name, file_id)\n",
        "\n",
        "        # update elapsed time\n",
        "        elapsed_time = time_check()\n",
        "\n",
        "    complete_status = True\n",
        "\n",
        "print(f'All files processed.  Completed in: {elapsed_time} seconds')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6xRlnLvL9JylKn6AkQX1U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}